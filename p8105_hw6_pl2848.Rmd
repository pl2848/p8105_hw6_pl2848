---
title: "p8105_hw6_pl2848"
author: "Pei Liu"
date: "2022-12-01"
output: github_document
---

```{r}
# Loaded the library
library(tidyverse)
library(dplyr)
library(viridis)
library(viridisLite)
library(glmnet)
library(modelr)
library(ggplot2)
library(forcats)
library(corrplot)
library(mgcv)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

theme_set(theme_minimal() + theme(legend.position = "bottom"))
```

### Problem 1

To obtain a distribution for $\hat{r}^2$, we'll follow basically the same procedure we used for regression coefficients: draw bootstrap samples; the a model to each; extract the value I'm concerned with; and summarize. Here, we'll use `modelr::bootstrap` to draw the samples and `broom::glance` to produce `r.squared` values. 

```{r weather_df, cache = TRUE}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```


```{r}
weather_df %>% 
  modelr::bootstrap(n = 1000) %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x) ),
    results = map(models, broom::glance)) %>% 
  select(-strap, -models) %>% 
  unnest(results) %>% 
  ggplot(aes(x = r.squared)) + geom_density()
```

In this example, the $\hat{r}^2$ value is high, and the upper bound at 1 may be a cause for the generally skewed shape of the distribution. If we wanted to construct a confidence interval for $R^2$, we could take the 2.5% and 97.5% quantiles of the estimates across bootstrap samples. However, because the shape isn't symmetric, using the mean +/- 1.96 times the standard error probably wouldn't work well.

We can produce a distribution for $\log(\beta_0 * \beta1)$ using a similar approach, with a bit more wrangling before we make our plot.

```{r}
weather_df %>% 
  modelr::bootstrap(n = 1000) %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x) ),
    results = map(models, broom::tidy)) %>% 
  select(-strap, -models) %>% 
  unnest(results) %>% 
  select(id = `.id`, term, estimate) %>% 
  pivot_wider(
    names_from = term, 
    values_from = estimate) %>% 
  rename(beta0 = `(Intercept)`, beta1 = tmin) %>% 
  mutate(log_b0b1 = log(beta0 * beta1)) %>% 
  ggplot(aes(x = log_b0b1)) + geom_density()
```

As with $r^2$, this distribution is somewhat skewed and has some outliers. 

The point of this is not to say you should always use the bootstrap -- it's possible to establish "large sample" distributions for strange parameters / values / summaries in a lot of cases, and those are great to have. But it is helpful to know that there's a way to do inference even in tough cases. 




### Problem 2
```{r}
# read the data
homicide = read_csv("data/homicide-data.csv") %>% 
  janitor::clean_names() %>% 
  mutate(city_state = str_c(city, ", ", state),
         solve_status = as.factor(ifelse(disposition == "Closed by arrest", 1, 0)),
         victim_age = as.numeric(victim_age)) %>% 
  filter(!city_state %in% c("Dallas, TX", "Phoenix, AZ",  "Kansas City, MO", "Tulsa, AL") &
           victim_sex != "Unknown" &
         victim_race %in% c("White" ,"Black"))%>% 
  drop_na()

homicide
```

Obtain the estimate and confidence interval of the adjusted odds ratio for solving homicides comparing male victims to female victims keeping all other variables fixed, stored the result in fit_logistic_MD.
```{r}
fit_logistic_MD = 
  homicide %>% 
  filter(city_state == "Baltimore, MD") %>% 
  mutate(victim_sex = as.factor(victim_sex)) %>% 
  glm(solve_status ~ victim_age + victim_race + victim_sex, data = ., family = binomial()) %>% 
  broom::tidy() %>% 
  mutate(OR = exp(estimate),
         lower_ci = exp(estimate - std.error*1.96),
         upper_ci = exp(estimate + std.error*1.96)) %>%
  select(term, OR, lower_ci, upper_ci) %>% 
  filter(term == "victim_sexMale") %>% 
  knitr::kable(digits = 3) 


fit_logistic_MD
```


```{r}
# Build a function to do logistic regression and return the result
fit_logistic = function(citystate) {
  
  result = homicide %>% 
  filter(city_state == citystate) %>% 
  glm(solve_status ~ victim_age + victim_race + victim_sex, data = ., family = binomial()) %>% 
  broom::tidy() %>% 
  mutate(OR = exp(estimate),
         lower_ci = exp(estimate - std.error*1.96),
         upper_ci = exp(estimate + std.error*1.96)) %>%
  select(term, OR, lower_ci, upper_ci) %>% 
    filter(term == "victim_sexMale")
  
  return(result)

  }
 
# Apply the function to each city state
logistic_reg_city_state = tibble(city_state = unique(homicide$city_state),
       result = map(city_state, fit_logistic)) %>% 
  unnest()


logistic_reg_city_state
```

Create a plot that shows the estimated ORs and CIs for each city. Organize cities according to estimated OR, and comment on the plot.

The boxplot shows adjusted ORs and 95% of each city in the US. New York has lowest adjusted odds ratio for solving homicides comparing male victims to female victims keeping all other variables fixed, while Albuquerque has the high odds ratio.  Most of the cities have odds ratio smaller than 1. Fresno, stockton and Albuquerque have very wide confidence interval compared with others. COnfidence interval for cities with larger ORs is also higher.
```{r}
# Created the boxplot of estimated OR and its 95% CI 
plot1 = logistic_reg_city_state %>% 
  mutate(city_state = fct_reorder(city_state, OR)) %>% 
  ggplot(aes(x = city_state, y = OR))+ 
  geom_point(alpha = .5) +
  geom_boxplot() + 
  geom_errorbar(aes(ymin = lower_ci, ymax = upper_ci), width = 0.8) +
  labs(
    title = "Adjusted OR and 95% CI for solving homicides comparing male victims to female victims",
    x = "City, State",
    y = "Adjusted OR with 95% CI"
  ) +
  theme(legend.position = "bottom",
        axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) 

# We can see that New York, NY has the lowest the odds ratio for solving homicides comparing male victims to female victims, while Albuquerque, NM has the highet (hoding other variables fixed). The confidence interval for the city states with higher ORs are larger compared with some cities with small ORs.
plot1
```




### Problem 3
```{r}
# Import the data
birthweight = read_csv("data/birthweight.csv") 

birthweight
```


```{r}
# Check missing values, there is no missing value for every column.
colSums(is.na(birthweight))
# check unique values for each columns. For pnumlbw and pnumsga, we only have one unique value 0, so there is no need to include these variables into our model.
apply(birthweight, 2, function(x) length(unique(x)))
unique(birthweight$pnumlbw)
unique(birthweight$pnumsga)
```

To get an overview of coeffienits between variables, I make the corelation matrix and displayed it via heat map.
```{r}
# correlation plot. Deleted two variables that only have one unique value.
correlation_plot = birthweight %>% 
  select(-pnumlbw, -pnumsga) %>% 
  cor() %>% 
  corrplot(type = "upper", diag = FALSE)

correlation_plot
```

According to the heat map, the variables that have relatively high correlation to bwt are: blength, bhead, gaweeks. 

Since I want to use a mlr model and our x is less than 20 (not that much), I can use backward elimination to get the optimal model.

First, I fit regression using all variables
```{r}
# Prepare a clean dataset
brw_clean = birthweight %>% 
  select(-pnumlbw, -pnumsga) %>% 
  mutate(babysex = as.factor(babysex),
         frace = as.factor(frace),
         malform = as.factor(malform),
         mrace = as.factor(mrace))

# fit regression using all predictors
mult.fit = lm(bwt ~ ., data = brw_clean)
summary(mult.fit)
```

Then, the idea is to take out non-significant variables one at a time starting with the highest p-value (But I used AIC instead). Here, I use one function to help me to do it. 

I think the best_mlr makes sense, because the variables that have low correlations are excluded and the remaining variables are all reasonable and could have potential effect to body weight. So I decided to use the result from backwards elimination as my prediction model.

```{r}
# The best model using backward elimination
best_mlr = step(mult.fit, direction='both', scope = formula(mult.fit))

# Tidy the model and display the result in dataframe
backward_selection = best_mlr %>% 
  broom::tidy()

backward_selection
```

show a plot of model residuals against fitted values - use add_predictions and add_residuals in making this plot.
```{r}
# Create the dataset for the plot
residual_plot = brw_clean %>% 
  modelr::add_predictions(best_mlr)  %>% 
  modelr::add_residuals(best_mlr) %>% 
  ggplot(aes(x = pred, y = resid)) + 
  geom_point() +
  labs(
    title = "Model residuals vs fitted values",
    x = "Fitted Value",
    y = "Residuals"
  )

residual_plot
```
To compare my model to the other two, I first:

Split train and test dataset
```{r}
cv_df =
  crossv_mc(brw_clean, 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))
```

ad then fit models to training data and obtain corresponding RMSEs for the testing data
```{r}
cv_df = cv_df %>%  
  mutate(
    model1  = map(train, ~lm(bwt ~ blength + gaweeks,data = .x)),
    model2  = map(train, ~lm(bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex + blength*babysex + bhead*blength*babysex, data = .x)),
    model3  = map(train, ~lm(bwt ~ babysex + bhead + blength + delwt + fincome + gaweeks + 
    mheight + mrace + parity + ppwt + smoken, data = .x))) %>% 
  mutate(
    rmse_1 = map2_dbl(model1, test, ~rmse(model = .x, data = .y)),
    rmse_2 = map2_dbl(model2, test, ~rmse(model = .x, data = .y)),
    rmse_3 = map2_dbl(model3, test, ~rmse(model = .x, data = .y)))
```

Lastly, I plot the prediction error distribution for each candidate model
```{r}
plot = cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
plot
```


We can see from the violin plot that model 3 (lm(bwt ~ babysex + bhead + blength + delwt + fincome + gaweeks + mheight + mrace + parity + ppwt + smoken, data = .x)) has the smallest RMSE, which means that my selected model has the highest accuracy among three tested models. That make sense, cause I used stepwise selection, and it will return the optimal model. Model 2 that consider interaction, also has higher predcition accuracy. But still, I will choose my model as final model.

